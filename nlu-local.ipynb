{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "Install the required libraries to be able to connect to IBM Db2 Warehouse on the cloud.\n",
    "Also set environment variable DYLD_LIBRARY_PATH to point to the correct install for ibm_db package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm_db in /Users/kozhaya/Documents/MyFiles/software/anaconda3/envs/python2/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kozhaya/Documents/MyFiles/software/anaconda3/envs/python2/lib/python2.7/site-packages/clidriver/lib\n"
     ]
    }
   ],
   "source": [
    "# Provide complete path to your python site-packages install\n",
    "PYTHON_INSTALL=\"YOUR_PYTHON_SITE_PACKAGES_INSTALL_PATH\"\n",
    "LIB_PATH=PYTHON_INSTALL + \"/clidriver/lib\"\n",
    "ICC_PATH=LIB_PATH + \"/icc\"\n",
    "print(LIB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kozhaya/Documents/MyFiles/software/anaconda3/envs/python2/lib/python2.7/site-packages/clidriver/lib:/Users/kozhaya/Documents/MyFiles/software/anaconda3/envs/python2/lib/python2.7/site-packages/clidriver/lib/icc:$DYLD_LIBRARY_PATH\n"
     ]
    }
   ],
   "source": [
    "os.environ['DYLD_LIBRARY_PATH'] = LIB_PATH + \":\" + ICC_PATH + \":\" + \"$DYLD_LIBRARY_PATH\"\n",
    "print(os.environ['DYLD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kozhaya/Documents/MyFiles/software/anaconda3/envs/python2/lib/python2.7/site-packages/clidriver/lib:/Users/kozhaya/Documents/MyFiles/software/anaconda3/envs/python2/lib/python2.7/site-packages/clidriver/lib/icc:$DYLD_LIBRARY_PATH\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['DYLD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "import time\n",
    "import pandas\n",
    "import ibm_db_dbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to DB2 Warehouse\n",
    "Get the credentials for your DB2 Warehouse on the cloud instance. To do so, log into your IBM Cloud account and then on top left, click on the menu icon and then select Dashboard.\n",
    "![IBM Cloud Dashboard](./files/dashboard.png \"Dashboard\")\n",
    "\n",
    "Next click on your DB2 Warehouse instance to launch that instance and on that page, select Service Credentials from the left navigation column.\n",
    "\n",
    "This should return the credentials required to access your service.\n",
    "Specifically, select the value for \"dsn\" key as shown in the following image:\n",
    "\n",
    "![DB2 Warehouse Service Credentials](./files/db2_creds.png \"Dashboard\")\n",
    "\n",
    "Include that value in the next cell to create a connection to your DB2 Warehouse on the Cloud instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = ibm_db.connect(dsn,\"\",\"\")\n",
    "pconn = ibm_db_dbi.Connection(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read data from DB2 table into Pandas dataframe\n",
    "Specify the table you'd like to read from DB2 into a Pandas dataframe. In the example below, I load the data from table DASH6296.DSX_CLOUDANT_SINGERS_TWEETS into a df pandas dataframe. Depending on how large your table is, this may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandasDF = pandas.read_sql('SELECT * FROM DASH6296.DSX_CLOUDANT_SINGERS_TWEETS', pconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198070, 24)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot dimensions of the Pandas dataframe\n",
    "pandasDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify NLU Credentials\n",
    "Next, you need to specify the credentials for your Watson Natural Language Understanding (NLU) service. If you don't have an NLU service, you can create one by following [these instructions](https://console.bluemix.net/docs/services/natural-language-understanding/getting-started.html#getting-started-tutorial) and obtaining the service credentials. You need to specify the URL, username, and password.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials_json= {\n",
    "    \"nlu_url\":\"YOUR_WATSON_NLU_URL\",\n",
    "    \"nlu_username\": \"YOUR WATSON NLU USERNAME\",\n",
    "\t\"nlu_password\": \"YOUR WATSON NLU PASSWORD\",\n",
    "\t\"nlu_version\": \"2017-02-27\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watson NLU Enrichment Definition\n",
    "In this cell, import the Watson Developer Cloud Python SDK, parse the\n",
    "NLU credentials, and define the function to enrich text with NLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import watson_developer_cloud\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 import Features, SentimentOptions, KeywordsOptions\n",
    "from watson_developer_cloud import WatsonException\n",
    "\n",
    "## Define credentials for NLU service\n",
    "nlu_url = credentials_json['nlu_url']\n",
    "nlu_username=credentials_json['nlu_username']\n",
    "nlu_password=credentials_json['nlu_password']\n",
    "nlu_version=credentials_json['nlu_version']\n",
    "nlu = watson_developer_cloud.NaturalLanguageUnderstandingV1(version = nlu_version,\n",
    "                                                            username = nlu_username,\n",
    "                                                            password = nlu_password)\n",
    "\n",
    "## Send text to NLU and extract Sentiment and Keywords\n",
    "## Make sure text is utf-8 encoded\n",
    "def enrichNLU(text):\n",
    "    utf8text = text.encode(\"utf-8\")\n",
    "    # In python3, need to decode to string\n",
    "    utf8text = utf8text.decode('utf-8')\n",
    "    \n",
    "    try:\n",
    "        result = nlu.analyze(text = utf8text, features = Features(sentiment=SentimentOptions(),keywords=KeywordsOptions()))\n",
    "        sentiment = result['sentiment']['document']['score']\n",
    "        sentiment_label = result['sentiment']['document']['label']\n",
    "        keywords = list(result['keywords'])  \n",
    "    except WatsonException:\n",
    "        result = None\n",
    "        sentiment = 0.0\n",
    "        sentiment_label = None\n",
    "        keywords = None\n",
    "    return sentiment, sentiment_label, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sample text utterance for testing NLU\n",
    "## Skip this cell unless you want to run a quick test in which case \n",
    "## you can un-comment the following lines and running the cell\n",
    "#t = \"I am really frustrated with this poor service\"\n",
    "#nlu_results = enrichNLU(t)\n",
    "#print(nlu_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a Random Sample of Records\n",
    "Next, we will extract a randome rample of records to run NLU enrichment on. This is needed to make sure we don't exceed our limit of free NLU calls per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 24)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numrecords = 500.0\n",
    "fraction = numrecords/pandasDF.shape[0]\n",
    "dfsample = pandasDF.sample(frac=fraction, replace=False)\n",
    "# verify extracted sample is the correct size\n",
    "dfsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLU Enrichment\n",
    "Next, we run the NLU enrichment on all records in the extracted sample. \n",
    "We time the run to report how long did the execution take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total run time is: ', 200.57519388198853)\n"
     ]
    }
   ],
   "source": [
    "## This calls the enrichNLU function which accesses the Watson NLU API\n",
    "start_time = time.time()\n",
    "dfsample['SENTIMENT'],dfsample['SENTIMENT_LABEL'],\\\n",
    "dfsample['KEYWORDS'] = zip(*dfsample['TEXT_CLEAN'].map(enrichNLU))\n",
    "#print(dfsample)\n",
    "print(\"total run time is: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 27)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the size of the enriched sample, you should see 3 additional \n",
    "# columns compares to the initial dataframe\n",
    "dfsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
